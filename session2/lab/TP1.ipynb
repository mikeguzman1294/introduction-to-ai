{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Artificial Intelligence - Supervised Learning lab Session Part 1\n",
    "--\n",
    "At the end of this session, you will be able to : \n",
    "- Perform basic supervised learning tasks using sklearn.\n",
    "- Learn the basics of pytorch in this [tutorial](Pytorch_tutorial.ipynb) (this can be done in parallel that the previous step if you work by groups of two)\n",
    "- Apply supervised learning on PyRat datasets, in two cases (predicting the winner from the start configuration, and training a classifer to predict the next movement to play)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tqdm package is useful to visualize progress with long computations. \n",
    "# Install it using pip. \n",
    "import tqdm\n",
    "import numpy as np\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Basics of machine learning using sklearn\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn is a very powerful package that implements most machine learning methods. sklearn also includes cross-validation procedures in order to prevent overfitting, many useful metrics and data manipulation techniques that enables very careful experimentations with machine learning. It is also very straightforward to use. We will introduce a few basic concepts of sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it is very easy to simulate data with sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function make_blobs to generate clouds of points with $d=2$, and visualize them using the function scatter from matplotlib.pyplot. You can generate as many samples as you want.You can generate several clouds of points using the argument centers. We recommend using random_state=0 so that your results are from the same distribution as our tests.\n",
    "\n",
    "Vocabulary : n_samples is the number of generated samples, n_features is $d$ (number of dimensions), centers is the number of classes. \n",
    "\n",
    "Hint : you can use the output \"y\" as an argument for the color argument (\"c\") of the scatter function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### CELL TO BE COMPLETED - Generate blobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELL TO BE COMPLETED - Plot.\n",
    "### Don't forget to import pyplot and use %matplotlib inline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use other arguments from make_blobs in order to change the variance of the blobs, or the coordinates of their center. You can also experiment on higher dimension, although it becomes difficult to visualize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has many other data generators, as well as ways to load standard datasets of various sizes. Check them out here: \n",
    "\n",
    "http://scikit-learn.org/stable/datasets/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generated a simple dataset, let's try to do a basic supervised learning approach. \n",
    "\n",
    "First, in order to mesure the ability of the model to generalize, we have to split the dataset into a training set and a test set. The test set is the part of the dataset that the model will not see during the training and will be used as a proxy for your \"real world\" examples.\n",
    "\n",
    "<center><img src=\"https://cdn-images-1.medium.com/max/1600/1*u03UsvBGwkYD4E7BObpcaw.png\"></center>\n",
    "<center><small>Image taken from https://towardsdatascience.com/machine-learning-workflow-on-diabetes-data-part-01-573864fcc6b8</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, you can use the train_test_split function to split datasets.\n",
    "\n",
    "Try to split the dataset you previously generated (the blobs) into x_train, x_test, y_train, y_test, with 80% in x_train and 20% in x_test. Set random_state = 0 so that the function always returns the same split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CELL TO BE COMPLETED \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes of the generated vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, x_blobs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a K-Nearest Neighbor classifier to test whether we can classify this dataset. Create a <b>classifier</b>, train it using your <b> training set </b> and evaluate it by its <b>accuracy</b> on both <b>the train and test sets</b>. \n",
    "\n",
    "In K-Nearest Neighbor classification (also known as KNN), when you want to predict the class of an object, you look at the K (an hyperparameter) nearest examples from the training (using a distance metric, in our case the euclidean distance). This object is then classified by a majority vote among its neighbors. In other words, the class of the object is the most common class among its neighbours.\n",
    "\n",
    "To use a Nearest Neighbor with sklearn, you have to use the class [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier).\n",
    "\n",
    "The sklearn API is consistent. This means that for almost every method they propose you can train it using [object.fit](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit), you can use it to make prediction with [object.predict](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict) and finally verify the <b>accuracy</b> of the method using [object.score](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELL TO BE COMPLETED - Train the classifier and get the accuracy in both sets.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 1\n",
    "classifier = KNeighborsClassifier(n_neighbors=k, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your classifier should have a train accuracy of 1, while the test accuracy should be high but not perfect.\n",
    "\n",
    "This is caused by the bias-variance trade-off. The 1-NN classifier always has a bias of 0 (it perfectly classifies the training set) but it has a high variance given that having one more example in the training set can completely change a decision.\n",
    "\n",
    "Try to avoid having such a high variance, test different values of k and plot the accuracies given the different values of the hyperparameter k. \n",
    "\n",
    "If you have time, we advise you to do the same analysis but varying the train/test split size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL TO BE COMPLETED - Train networks with varying k.\n",
    "train_acc = list()\n",
    "test_acc = list()  # list storing the test set accuracies\n",
    "test_ks = range(1,25)  # list containing values of k to be tested\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your classifier is trained, and bias-variance analysed, it is time to look at other metrics based on your results. It is important to remember that accuracy is a key metric, but it is not the <b> only </b> metric you should be focusing on.\n",
    "\n",
    "Print a [classification report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) and a [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) for both training and test sets.\n",
    "\n",
    "In the classification report, you are going to see 3 new metrics. They are really important because the accuracy does not show a complete portrait of your results.\n",
    "\n",
    "* Precision: What is the percentage of cases your model correctly classified while predicting a given class?\n",
    "* Recall: What is the percentage of cases your model correctly classified while predicting examples belonging to a given class?\n",
    "* F1 Score: Harmonic mean from precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "report = classification_report(y_true=y_train,y_pred=y_pred_train)\n",
    "matrix = confusion_matrix(y_true=y_train,y_pred=y_pred_train)\n",
    "print(\"Training Set:\")\n",
    "print(report)\n",
    "print(matrix)\n",
    "plt.matshow(matrix)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Real class\")\n",
    "plt.ylabel(\"Predicted class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELL TO BE COMPLETED - Generate the report and confusion matrix for the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you are going to plot the decision boundaries of our model. Use the function plot_boundaries given below. You can only do this if the tensor representing your data is two dimensional.\n",
    "\n",
    "This function will test our model with values ranging from the smallest x to the highest x and from the lowest y to the highest y, each varying by $h$ and plot it nicely. [Link to the original implementation.](http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_boundaries(classifier,X,Y,h=0.2):\n",
    "    x0_min, x0_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x1_min, x1_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    x0, x1 = np.meshgrid(np.arange(x0_min, x0_max,h),\n",
    "                         np.arange(x1_min, x1_max,h))\n",
    "    dataset = np.c_[x0.ravel(),x1.ravel()]\n",
    "    Z = classifier.predict(dataset)\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(x0.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(x0, x1, Z)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y,\n",
    "                edgecolor='k', s=20)\n",
    "    plt.xlim(x0.min(), x0.max())\n",
    "    plt.ylim(x1.min(), x1.max())\n",
    "plot_boundaries(classifier,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the winner in PyRat based on the initial cheese configuration\n",
    "--\n",
    "\n",
    "Use the code from TP0 in order to generate a PyRat dataset (X,y) of initial cheese configuration X each corresponding to a label of winner in y. \n",
    "\n",
    "The goal of the next part is to perform supervised learning on this dataset using a KNN classifier, as done above. Use the same metrics to estimate the performance of the classifier. \n",
    "\n",
    "We suggest that you start with a rather small maze, as the problem gets really high to solve in high dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch tutorial\n",
    "--\n",
    "Go [here](Pytorch_tutorial.ipynb) and perform the pytorch tutorial before moving to part 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 - Playing PyRat using Machine Learning by training a classifier to predict the next movement to play (or - Supervised Baseline for Pyrat Challenge)\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the folder of the lab session, in addition to this notebook, there is a subfolder \"supervised_playing\". \n",
    "\n",
    "Go into this folder and read the [README](supervised_playing/README.md). Then complete the files in the templates folder, in order to setup the training of a classifier to play pyrat!\n",
    "\n",
    "Note that you will have to define a model in pytorch, so you have to do the pytorch tutorial first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the trained classifier play against the greedy? \n",
    "\n",
    "Now it's up to you to explore other possibilities to make a better player. A few starting points: \n",
    "- Change the \"canvas\" to add more information, such as the position of the other player. \n",
    "- Find more clever strategies to cross validate training, in order to enable a better estimate of generalization\n",
    "- Work on simpler versions of the problem (smaller maze, less cheese, ..) , to develop a better understanding of learning.\n",
    "- Generate datasets using another algorithm than the greedy (eg, a variant that surely beats the greedy).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work to be done for P1 Project\n",
    "--\n",
    "\n",
    "You have to choose a machine learning method, and test it on at least one of the two supervised learning tasks we propose here : predicting the winner, or playing pyrat by predicting the next move. \n",
    "\n",
    "You are free to explore ! \n",
    "\n",
    "A few hints for the \"predicting winner\" task : \n",
    "\n",
    "- Try to make a binary classification between Pyrat and python wins.\n",
    "- Try to improve the classification performance of the draw class by using a balanced dataset for the three classes (i.e. try to have the same number of examples in each class).\n",
    "- Try to change the parameters of the maze (mazeWidth, mazeHeight, piecesOfCheese, ...). \n",
    "\n",
    "A few hints for the \"playing pyrat\" task : \n",
    "- Try to change the parameters of the maze (mazeWidth, mazeHeight, piecesOfCheese, ...). \n",
    "\n",
    "\n",
    "*When working on your project P1, we expect you to investigate these last questions in order to explore the method you chose.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python36964bitbaseconda6c8d87063a18461ca77c51084a3826c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
