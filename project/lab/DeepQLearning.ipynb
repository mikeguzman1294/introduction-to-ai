{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO7RHsHA7OFT"
   },
   "source": [
    "# Pyrat Deep Q-Learning Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYJC74id7RfC"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFq5e_b57Zdp"
   },
   "source": [
    "Required libraries for PyRat Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pLZtqLrz7HZJ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from AIs import manh, numpy_rl_reload\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "### The game.py file describes the simulation environment, including the generation of reward and the observation that is fed to the agent.\n",
    "import game\n",
    "\n",
    "### The rl.py file describes the reinforcement learning procedure, including Q-learning, Experience replay, and a pytorch model to learn the Q-function.\n",
    "### SGD is used to approximate the Q-function.\n",
    "import rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1aSLl_Q7f3y"
   },
   "source": [
    "Libraries for training the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PWu3zad67hSu"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import inspect\n",
    "\n",
    "# Personal libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3fm8w0x7ny3"
   },
   "source": [
    "This is a very unknown but cool library that can help you build a neural network.\n",
    "\n",
    "It helps you **calculate the shape of the tensor outputs** of network operations.\n",
    "\n",
    "[Tensorshape Library Documentation](https://pypi.org/project/torchshape/0.0.8/#description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uIOkXOcR7tge"
   },
   "outputs": [],
   "source": [
    "import subprocess # For importing missing libraries real-time\n",
    "try:\n",
    "    from torchshape import tensorshape\n",
    "except:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'torchshape'])\n",
    "    from torchshape import tensorshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifmdhCiq7v3l"
   },
   "source": [
    "Define our **device** as the first visible CUDA device if we have CUDA available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "COc2OYpj7xwF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device '+ str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLrIHhZo70ZB"
   },
   "source": [
    "## PyRat Game Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhC-8TfL73pX"
   },
   "source": [
    "Details of the game:\n",
    "\n",
    "1️⃣ The **opponent** plays using a deterministic strategy: a **greedy algorithm** always targetting the closest piece of cheese as next target. - The distance to pieces of cheese is calculated using Manhattan Distance (= L1 distance). The code is in AIs/manh.py.\n",
    "\n",
    "2️⃣ The maze does **not** include **walls** (option -d 0)\n",
    "\n",
    "3️⃣ The maze does **not** include **mud** (option -md 0)\n",
    "\n",
    "4️⃣The **dimension** of the maze is **21 x 15** (default parameter)\n",
    "\n",
    "5️⃣The number of **pieces of cheese** is **40** (option -p 40)\n",
    "\n",
    "6️⃣ The **maze** is non **symmetric** (option --nonsymmetric)\n",
    "\n",
    "You can therefore run a 1000 game test simulations using the following command:\n",
    "\n",
    "<pre>python pyrat.py -d 0 -md 0 -p 40 -x 21 -y 15 --rat AIs/manh.py --python AIs/YOURAIHERE --nonsymmetric --nodrawing --tests 1000 --synchronous</pre>\n",
    "\n",
    "Furthermore, you can run a visual game simulation with a command following the next structure:\n",
    "\n",
    "<pre>python pyrat.py -p 40 -x 21 -y 15 -d 0 -md 0 --rat AIs/manh.py --python AIs/YOURAIHERE --nonsymmetric</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXCBPyNa77BM"
   },
   "source": [
    "## Train a model to approximate the Q-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuJe14GQ8Ch-"
   },
   "source": [
    "Definitions :\n",
    "- An iteration of training is called an **Epoch**. It correspond to a full play of a PyRat game. \n",
    "- An **experience** is a set of  vectors < s, a, r, s’ > describing the consequence of being in state s, doing action a, receiving reward r, and ending up in state s'.\n",
    "- Look at the file rl.py to see how the **experience replay buffer** is implemented. \n",
    "- A **batch** is a set of experiences we use for training during one epoch. We draw batches from the experience replay buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBNFi1op8FIn"
   },
   "source": [
    "### Create the simulated game environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NidPyze8Hdw"
   },
   "source": [
    "Set the parameters for the Pyrat game simulated environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hSH85UE68JbZ"
   },
   "outputs": [],
   "source": [
    "width = 21  # Size of the playing field\n",
    "height = 15  # Size of the playing field\n",
    "cheeses = 40  # Number of cheeses in the game\n",
    "opponent = manh  # AI used for the opponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3jQSL0X8MMe"
   },
   "source": [
    "Create the Pyrat simulated environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "liCUxE668Q8b"
   },
   "outputs": [],
   "source": [
    "env = game.PyRat(width=width, height=height, opponent=opponent, cheeses=cheeses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhaGBtt_8UYI"
   },
   "source": [
    "Show the **shape of an observation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Gjnevklg8Wl-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 29, 41, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_observation = torch.FloatTensor(env.observe())\n",
    "test_observation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0SDKk5x8XTx"
   },
   "source": [
    "We have to be careful with this default shape since convolutional layers expect as inputs tensors in the form of:\n",
    "\n",
    "<pre>(batch size, number of channels, height, width)</pre>\n",
    "\n",
    "The environment throws the tensor in the shape, which is **WRONG**:\n",
    "\n",
    "<pre>(batch size, height, width, number of channels)</pre>\n",
    "\n",
    "We can transform the tensor in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x2uFBx718bv0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 29, 41])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_observation = test_observation.permute(0, 3, 1, 2)\n",
    "test_observation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfYoYbAo8eBT"
   },
   "source": [
    "### Create the experience replay buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn1w8wvL8hHy"
   },
   "source": [
    "Set the parameters for the experience replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xjU1cG338jFg"
   },
   "outputs": [],
   "source": [
    "max_memory = 1000  # Maximum number of experiences we are storing\n",
    "discount_factor=.97 # Discount factor for future rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puYkjOjg8nLl"
   },
   "source": [
    "Create the experience replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pQF5pGtk8o-U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_replay = rl.ExperienceReplay(max_memory=max_memory, discount=discount_factor)\n",
    "exp_replay.discount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIDIjfUc8rLM"
   },
   "source": [
    "### Q-Function Approximation Model Topologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PidICXyB8tTi"
   },
   "source": [
    "**Simple regressor** to predict the Q-values. Base Topology used and tested in course laboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "v4CvsVHE8vKy"
   },
   "outputs": [],
   "source": [
    "class MultiRegressor1FC(nn.Module):\n",
    "    def __init__(self, x_example, number_of_channels=1, number_of_regressors=4):\n",
    "        super(MultiRegressor1FC, self).__init__()\n",
    "        in_features = x_example.reshape(-1).shape[0]\n",
    "        self.nb_channels = number_of_channels\n",
    "        self.linear = nn.Linear(in_features, number_of_regressors)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        return self.linear(x)\n",
    "\n",
    "    def load(self):\n",
    "        if self.nb_channels == 1:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_ANN1FC_1channel.pt'))\n",
    "        else:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_ANN1FC_2channel.pt'))\n",
    "\n",
    "    def save(self):\n",
    "        if self.nb_channels == 1:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_ANN1FC_1channel.pt')\n",
    "        else:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_ANN1FC_2channel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 hidden layer regressor network** to predict the Q-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRegressor2FC(nn.Module):\n",
    "    def __init__(self, x_example, number_of_channels=1, number_of_regressors=4):\n",
    "        super(MultiRegressor2FC, self).__init__()\n",
    "        in_features = x_example.reshape(-1).shape[0]\n",
    "        self.nb_channels = number_of_channels\n",
    "        self.fc1 = nn.Linear(in_features, 16)\n",
    "        self.selu = nn.SELU()\n",
    "        self.linear = nn.Linear(16, number_of_regressors)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.selu(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "    def load(self):\n",
    "        if self.nb_channels == 1:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_ANN2FC_1channel.pt'))\n",
    "        else:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_ANN2FC_2channel.pt'))\n",
    "\n",
    "    def save(self):\n",
    "        if self.nb_channels == 1:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_ANN2FC_1channel.pt')\n",
    "        else:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_ANN2FC_2channel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTDkqxir8yxn"
   },
   "source": [
    "A **CNN multi-regressor** integrating **1 fully connected layer**. Expects **1 or 2 channels** as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "L_-spNQA8z1m"
   },
   "outputs": [],
   "source": [
    "class MultiRegressorCNN1FC(nn.Module):\n",
    "    def __init__(self, number_of_channels=1):\n",
    "        super().__init__()\n",
    "        self.nb_channels = number_of_channels\n",
    "        self.conv1 = nn.Conv2d(number_of_channels, 16, kernel_size=3) # output_shape = (1, 16, 27, 39)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2) # output_shape = (1, 16, 13, 19)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3) # output_shape = (1, 32, 11, 17)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2) # output_shape = (1, 32, 5, 8)\n",
    "        self.fc = nn.Linear(32 * 5 * 8, 4) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.reshape(x.shape[0],-1) # output_shape = (1280)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def load(self):\n",
    "        if self.nb_channels == 1:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_CNN1FC_1channel.pt'))\n",
    "        else:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_CNN1FC_2channel.pt'))\n",
    "\n",
    "    def save(self):\n",
    "        if self.nb_channels == 1:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_CNN1FC_1channel.pt')\n",
    "        else:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_CNN1FC_2channel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gaoybola83yL"
   },
   "source": [
    "Sanity check to confirm the dimensions of the tensors after each convolutional layer operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4jc9gCnO86b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after first Conv2d: (1, 16, 27, 39)\n",
      "Shape after first MaxPool2d: (1, 16, 13, 19)\n",
      "Shape after second Conv2d: (1, 32, 11, 17)\n",
      "Shape after second MaxPool2d: (1, 32, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "# Input shape which is the size of the canvas\n",
    "\n",
    "x_shape = (1, 1, 29, 41)\n",
    "\n",
    "# Default not passed parameters for Conv2d\n",
    "# stride=(1,1), padding=(0,0), dilation=(1,1), groups=1\n",
    "\n",
    "# First convolution operation\n",
    "op = nn.Conv2d(1, 16, kernel_size=3)\n",
    "x_shape = tensorshape(op, x_shape)\n",
    "print(f'Shape after first Conv2d: {x_shape}')\n",
    "\n",
    "# First maxpool operation\n",
    "op = nn.MaxPool2d(kernel_size=2)\n",
    "x_shape = tensorshape(op, x_shape)\n",
    "print(f'Shape after first MaxPool2d: {x_shape}')\n",
    "\n",
    "# Second convolution operation\n",
    "op = nn.Conv2d(16, 32, kernel_size=3)\n",
    "x_shape = tensorshape(op, x_shape)\n",
    "print(f'Shape after second Conv2d: {x_shape}')\n",
    "\n",
    "# Second maxpool operation\n",
    "op = nn.MaxPool2d(kernel_size=2)\n",
    "x_shape = tensorshape(op, x_shape)\n",
    "print(f'Shape after second MaxPool2d: {x_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lvlt9pcN89b9"
   },
   "source": [
    "Check that this model fits well the data with a small sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RaTC7Iry8_iH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the raw input tensor: torch.Size([1, 29, 41, 2])\n",
      "Shape of the output tensor: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create a test instance of the model\n",
    "test_model = MultiRegressorCNN1FC(env.observe().shape[3])\n",
    "\n",
    "# Get a sample observation of the game environment\n",
    "test_input_tensor = torch.FloatTensor(env.observe())\n",
    "print(f'Shape of the raw input tensor: {test_input_tensor.shape}')\n",
    "\n",
    "# Get an output given the sample input and an untrained model just to validate teh correct output size\n",
    "test_output_tensor = test_model(test_input_tensor)\n",
    "print(f'Shape of the output tensor: {test_output_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **CNN multi-regressor** integrating **2 fully connected layers**. Expects **1 or 2 channels** as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRegressorCNN2FC(nn.Module):\n",
    "    def __init__(self, number_of_channels=1):\n",
    "        super().__init__()\n",
    "        self.nb_channels = number_of_channels\n",
    "        self.conv1 = nn.Conv2d(number_of_channels, 16, kernel_size=3) # output_shape = (1, 16, 27, 39)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2) # output_shape = (1, 16, 13, 19)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3) # output_shape = (1, 32, 11, 17)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2) # output_shape = (1, 32, 5, 8)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 8, 16)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0],-1) # output_shape = (1280)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def load(self):\n",
    "        if self.nb_channels == 1:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_CNN2FC_1channel.pt'))\n",
    "        else:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_CNN2FC_2channel.pt'))\n",
    "\n",
    "    def save(self):\n",
    "        if self.nb_channels == 1:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_CNN2FC_1channel.pt')\n",
    "        else:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_CNN2FC_2channel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that this model fits well the data with a small sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the raw input tensor: torch.Size([1, 29, 41, 2])\n",
      "Shape of the output tensor: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create a test instance of the model\n",
    "test_model = MultiRegressorCNN2FC(env.observe().shape[3])\n",
    "\n",
    "# Get a sample observation of the game environment\n",
    "test_input_tensor = torch.FloatTensor(env.observe())\n",
    "print(f'Shape of the raw input tensor: {test_input_tensor.shape}')\n",
    "\n",
    "# Get an output given the sample input and an untrained model just to validate teh correct output size\n",
    "test_output_tensor = test_model(test_input_tensor)\n",
    "print(f'Shape of the output tensor: {test_output_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **CNN multi-regressor** integrating **3 fully connected layers**. Expects **1 or 2 channels** as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRegressorCNN3FC(nn.Module):\n",
    "    def __init__(self, number_of_channels=1):\n",
    "        super().__init__()\n",
    "        self.nb_channels = number_of_channels\n",
    "        self.conv1 = nn.Conv2d(number_of_channels, 16, kernel_size=3) # output_shape = (1, 16, 27, 39)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2) # output_shape = (1, 16, 13, 19)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3) # output_shape = (1, 32, 11, 17)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2) # output_shape = (1, 32, 5, 8)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 8, 10)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(10, 4)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0],-1) # output_shape = (1280)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def load(self):\n",
    "        if self.nb_channels == 1:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_CNN3FC_1channel.pt'))\n",
    "        else:\n",
    "            self.load_state_dict(torch.load('save_rl/weights_CNN3FC_2channel.pt'))\n",
    "\n",
    "    def save(self):\n",
    "        if self.nb_channels == 1:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_CNN3FC_1channel.pt')\n",
    "        else:\n",
    "            torch.save(self.state_dict(), 'save_rl/weights_CNN3FC_2channel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that this model fits well the data with a small sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the raw input tensor: torch.Size([1, 29, 41, 2])\n",
      "Shape of the output tensor: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create a test instance of the model\n",
    "test_model = MultiRegressorCNN3FC(env.observe().shape[3])\n",
    "\n",
    "# Get a sample observation of the game environment\n",
    "test_input_tensor = torch.FloatTensor(env.observe())\n",
    "print(f'Shape of the raw input tensor: {test_input_tensor.shape}')\n",
    "\n",
    "# Get an output given the sample input and an untrained model just to validate teh correct output size\n",
    "test_output_tensor = test_model(test_input_tensor)\n",
    "print(f'Shape of the output tensor: {test_output_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Q-Function Approximation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAhwL-NS9Mmx"
   },
   "source": [
    "Let's **initialize** the neural network of your choice!\n",
    "\n",
    "Un-comment / comment to choose your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "inU7box49O_t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiRegressor2FC(\n",
       "  (fc1): Linear(in_features=2378, out_features=16, bias=True)\n",
       "  (selu): SELU()\n",
       "  (linear): Linear(in_features=16, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model parameters\n",
    "nb_channels = env.observe().shape[3]\n",
    "print(f'Number of channels: {nb_channels}')\n",
    "\n",
    "# Instantiate chosen model and move it to device\n",
    "\n",
    "# Simple regressor with 1 fully connected layer\n",
    "#model = MultiRegressor1FC(env.observe()[0], number_of_channels=nb_channels)\n",
    "\n",
    "# Simple regressor with 2 fully connected layers\n",
    "model = MultiRegressor2FC(env.observe()[0], number_of_channels=nb_channels)\n",
    "\n",
    "# CNN regressor with 1 fully connected layer\n",
    "#model = MultiRegressorCNN1FC(number_of_channels=nb_channels)\n",
    "\n",
    "# CNN regressor with 2 fully connected layers\n",
    "#model = MultiRegressorCNN2FC(number_of_channels=nb_channels)\n",
    "\n",
    "# CNN regressor with 3 fully connected layers\n",
    "#model = MultiRegressorCNN3FC(number_of_channels=nb_channels)\n",
    "\n",
    "#model.to(device=device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr1x0Q6x9RwF"
   },
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Adr3VkGP9TsH"
   },
   "source": [
    "Define a **loss function** and **optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ObqFCx2t9Wqp"
   },
   "outputs": [],
   "source": [
    "# Define the loss function as cross-entropy\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Set stochastic gradient descent as the optimizer\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
    "\n",
    "# Set Adam as the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu3DMdgD9Y9H"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zhJz2StX9byq"
   },
   "outputs": [],
   "source": [
    "number_of_batches = 8  # Number of batches per epoch\n",
    "batch_size = 32  # Number of experiences we use for training per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset global maximum cheese counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cheese = 0\n",
    "max_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cheese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2104.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training routine definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cukp__uh9s23"
   },
   "outputs": [],
   "source": [
    "def play(model, epochs, criterion, optimizer=None, train=True):\n",
    "\n",
    "    win_cnt = 0\n",
    "    lose_cnt = 0\n",
    "    draw_cnt = 0\n",
    "    win_hist = []\n",
    "    cheeses = []\n",
    "    \n",
    "    # Addition to track rewards\n",
    "    reward_cnt = 0\n",
    "    rewards = []\n",
    "    \n",
    "    steps = 0.\n",
    "    last_W = 0\n",
    "    last_D = 0\n",
    "    last_L = 0\n",
    "    \n",
    "    global max_cheese\n",
    "    global max_reward\n",
    "    \n",
    "    for e in tqdm(range(epochs)):\n",
    "        env.reset()\n",
    "        game_over = False\n",
    "\n",
    "        # Get the current state of the environment\n",
    "        state = env.observe()\n",
    "        \n",
    "        # Play a full game until game is over\n",
    "        while not game_over:\n",
    "            # Do not forget to transform the input of model into torch tensor\n",
    "            state = torch.FloatTensor(state)\n",
    "\n",
    "            # Predict the Q value for the current state\n",
    "            q_values = model(state)\n",
    "\n",
    "            # Pick the next action that maximizes the Q value\n",
    "            action = torch.argmax(q_values)\n",
    "            \n",
    "            # Apply action, get rewards and new state\n",
    "            previous_state = state.detach().clone()\n",
    "            state, reward, game_over= env.act(action)\n",
    "            \n",
    "            # Statistics            \n",
    "            reward_cnt += reward\n",
    "            \n",
    "            if game_over:\n",
    "                steps += env.round\n",
    "                if env.score > env.enemy_score:\n",
    "                    win_cnt += 1\n",
    "                elif env.score == env.enemy_score:\n",
    "                    draw_cnt += 1\n",
    "                else:\n",
    "                    lose_cnt += 1\n",
    "                cheese = env.score\n",
    "\n",
    "            # Create an experience array using previous state, the performed action, the obtained reward and the new state. The vector has to be in this order.\n",
    "            # Store in the experience replay buffer an experience and end game.\n",
    "            # Do not forget to transform the previous state and the new state into torch tensor.\n",
    "            # Create an experience array\n",
    "            experience = [torch.FloatTensor(previous_state), action, reward, torch.FloatTensor(state)]\n",
    "\n",
    "            # Store the experience in the experience replay buffer\n",
    "            exp_replay.remember(experience, game_over)\n",
    "            \n",
    "        win_hist.append(win_cnt)  # Statistics\n",
    "        cheeses.append(cheese)  # Statistics\n",
    "        \n",
    "        # Save the total reward of this episode and reset the episode reward counter\n",
    "        rewards.append(reward_cnt)        \n",
    "        reward_cnt = 0\n",
    "\n",
    "        if train:\n",
    "\n",
    "            # Train using experience replay. For each batch, get a set of experiences (state, action, new state) that were stored in the buffer. \n",
    "            # Use this batch to train the model.\n",
    "            \n",
    "            running_loss = 0\n",
    "            for b in range(number_of_batches):\n",
    "                # Get the batch data\n",
    "                states, Q = exp_replay.get_batch(model, batch_size=batch_size)\n",
    "                \n",
    "                # Fit the training data in mounted device\n",
    "                #states = states.to(device=device)                \n",
    "                #Q = Q.to(device=device)                \n",
    "               \n",
    "                # Compute the loss\n",
    "                loss = rl.train_on_batch(model, states, Q, criterion, optimizer)\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss\n",
    "            #print('[%d] loss: %.3f' % (e + 1, running_loss / number_of_batches))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            '''if e > 100 :  # Check to save\n",
    "                cheese_np = np.array(cheeses)\n",
    "                if cheese_np[-100:].sum() > max_cheese:\n",
    "                    max_cheese = cheese_np[-100:].sum()\n",
    "                    print(f\"New maximum cheese: {max_cheese}.\\nSaving model...\")\n",
    "                    model.save()'''\n",
    "                    \n",
    "            if e > 100 :  # Check to save\n",
    "                rewards_np = np.array(rewards)\n",
    "                if rewards_np[-100:].sum() > max_reward:\n",
    "                    max_reward = rewards_np[-100:].sum()\n",
    "                    print(f\"New maximum rewards: {max_reward}.\\nSaving model...\")\n",
    "                    model.save()   \n",
    "        \n",
    "        if (e+1) % 100 == 0:  # Statistics every 100 epochs\n",
    "            cheese_np = np.array(cheeses)\n",
    "            rewards_np = np.array(rewards)\n",
    "            string = \"Epoch {:03d}/{:03d} | Last 100 Reward {} | Last 100 Cheese {}| W/D/L {}/{}/{} | 100 W/D/L {}/{}/{} | 100 Steps {}\".format(\n",
    "                        e,epochs, rewards_np[-100:].sum(), \n",
    "                        cheese_np[-100:].sum(), win_cnt, draw_cnt, lose_cnt, \n",
    "                        win_cnt-last_W, draw_cnt-last_D, lose_cnt-last_L, steps/100)\n",
    "            print(string)\n",
    "        \n",
    "            steps = 0.\n",
    "            last_W = win_cnt\n",
    "            last_D = draw_cnt\n",
    "            last_L = lose_cnt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk6HOHPG9zUL"
   },
   "source": [
    "### Train the Q-learner with Experience replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUTdNoh-9eyi"
   },
   "source": [
    "If load, then the last saved result is loaded and training is continued. Otherwise, training is performed from scratch starting with random parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False\n",
    "\n",
    "if load:\n",
    "    model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "WEjgtpVI91sR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                             | 102/10000 [00:08<12:41, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 099/10000 | Last 100 Reward 1970.0 | Last 100 Cheese 1940.0| W/D/L 51/17/32 | 100 W/D/L 51/17/32 | 100 Steps 67.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                            | 202/10000 [00:16<14:24, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/10000 | Last 100 Reward 2006.0 | Last 100 Cheese 1957.5| W/D/L 107/31/62 | 100 W/D/L 56/14/30 | 100 Steps 66.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                           | 302/10000 [00:24<13:10, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/10000 | Last 100 Reward 2041.0 | Last 100 Cheese 1985.5| W/D/L 160/52/88 | 100 W/D/L 53/21/26 | 100 Steps 70.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                          | 402/10000 [00:33<13:34, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/10000 | Last 100 Reward 2005.0 | Last 100 Cheese 1961.0| W/D/L 208/72/120 | 100 W/D/L 48/20/32 | 100 Steps 69.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                          | 502/10000 [00:41<13:37, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/10000 | Last 100 Reward 2020.0 | Last 100 Cheese 1958.5| W/D/L 262/88/150 | 100 W/D/L 54/16/30 | 100 Steps 68.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                         | 602/10000 [00:50<13:18, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/10000 | Last 100 Reward 1972.0 | Last 100 Cheese 1936.0| W/D/L 313/101/186 | 100 W/D/L 51/13/36 | 100 Steps 68.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                        | 702/10000 [00:58<12:33, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699/10000 | Last 100 Reward 2052.0 | Last 100 Cheese 1997.0| W/D/L 374/116/210 | 100 W/D/L 61/15/24 | 100 Steps 67.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                       | 802/10000 [01:07<12:38, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/10000 | Last 100 Reward 2001.0 | Last 100 Cheese 1968.5| W/D/L 428/129/243 | 100 W/D/L 54/13/33 | 100 Steps 67.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████                                                                       | 902/10000 [01:15<12:04, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/10000 | Last 100 Reward 1999.0 | Last 100 Cheese 1952.5| W/D/L 481/141/278 | 100 W/D/L 53/12/35 | 100 Steps 68.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                     | 1000/10000 [01:23<12:29, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/10000 | Last 100 Reward 2040.0 | Last 100 Cheese 1984.0| W/D/L 546/149/305 | 100 W/D/L 65/8/27 | 100 Steps 64.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▍                                                                    | 1102/10000 [01:32<13:07, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1099/10000 | Last 100 Reward 2016.0 | Last 100 Cheese 1959.5| W/D/L 601/165/334 | 100 W/D/L 55/16/29 | 100 Steps 66.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▎                                                                   | 1202/10000 [01:40<12:03, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/10000 | Last 100 Reward 2024.0 | Last 100 Cheese 1980.0| W/D/L 654/180/366 | 100 W/D/L 53/15/32 | 100 Steps 68.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████                                                                   | 1302/10000 [01:49<11:52, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1299/10000 | Last 100 Reward 2019.0 | Last 100 Cheese 1966.0| W/D/L 714/196/390 | 100 W/D/L 60/16/24 | 100 Steps 66.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▊                                                                  | 1402/10000 [01:57<11:39, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1399/10000 | Last 100 Reward 1940.0 | Last 100 Cheese 1917.5| W/D/L 760/208/432 | 100 W/D/L 46/12/42 | 100 Steps 67.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▌                                                                 | 1502/10000 [02:05<12:19, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1499/10000 | Last 100 Reward 1997.0 | Last 100 Cheese 1953.5| W/D/L 813/223/464 | 100 W/D/L 53/15/32 | 100 Steps 65.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▎                                                                | 1602/10000 [02:14<11:42, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1599/10000 | Last 100 Reward 2006.0 | Last 100 Cheese 1950.5| W/D/L 867/240/493 | 100 W/D/L 54/17/29 | 100 Steps 69.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████                                                                | 1702/10000 [02:22<11:09, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1699/10000 | Last 100 Reward 2022.0 | Last 100 Cheese 1964.0| W/D/L 917/258/525 | 100 W/D/L 50/18/32 | 100 Steps 70.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▉                                                               | 1802/10000 [02:31<10:53, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1799/10000 | Last 100 Reward 1992.0 | Last 100 Cheese 1959.5| W/D/L 971/271/558 | 100 W/D/L 54/13/33 | 100 Steps 66.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▋                                                              | 1902/10000 [02:39<11:26, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1899/10000 | Last 100 Reward 1952.0 | Last 100 Cheese 1927.0| W/D/L 1016/288/596 | 100 W/D/L 45/17/38 | 100 Steps 69.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 2002/10000 [02:48<11:22, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1999/10000 | Last 100 Reward 2041.0 | Last 100 Cheese 1987.5| W/D/L 1074/303/623 | 100 W/D/L 58/15/27 | 100 Steps 69.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▏                                                            | 2102/10000 [02:56<11:10, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2099/10000 | Last 100 Reward 2012.0 | Last 100 Cheese 1972.0| W/D/L 1132/316/652 | 100 W/D/L 58/13/29 | 100 Steps 68.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▉                                                            | 2202/10000 [03:04<10:39, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2199/10000 | Last 100 Reward 2007.0 | Last 100 Cheese 1968.5| W/D/L 1184/335/681 | 100 W/D/L 52/19/29 | 100 Steps 68.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▋                                                           | 2302/10000 [03:13<10:45, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2299/10000 | Last 100 Reward 2058.0 | Last 100 Cheese 2000.0| W/D/L 1244/353/703 | 100 W/D/L 60/18/22 | 100 Steps 68.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▊                                                           | 2308/10000 [03:13<10:59, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New maximum rewards: 2072.0.\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▍                                                          | 2402/10000 [03:21<10:40, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2399/10000 | Last 100 Reward 2011.0 | Last 100 Cheese 1958.5| W/D/L 1298/370/732 | 100 W/D/L 54/17/29 | 100 Steps 68.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▎                                                         | 2500/10000 [03:29<10:29, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2499/10000 | Last 100 Reward 2012.0 | Last 100 Cheese 1962.0| W/D/L 1351/387/762 | 100 W/D/L 53/17/30 | 100 Steps 67.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████                                                         | 2602/10000 [03:38<10:22, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2599/10000 | Last 100 Reward 1992.0 | Last 100 Cheese 1959.5| W/D/L 1401/407/792 | 100 W/D/L 50/20/30 | 100 Steps 68.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▊                                                        | 2702/10000 [03:46<10:06, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2699/10000 | Last 100 Reward 1956.0 | Last 100 Cheese 1909.5| W/D/L 1448/416/836 | 100 W/D/L 47/9/44 | 100 Steps 70.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▌                                                       | 2802/10000 [03:55<09:49, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2799/10000 | Last 100 Reward 1954.0 | Last 100 Cheese 1922.5| W/D/L 1497/429/874 | 100 W/D/L 49/13/38 | 100 Steps 68.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████▎                                                      | 2900/10000 [04:03<11:18, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2899/10000 | Last 100 Reward 2018.0 | Last 100 Cheese 1976.5| W/D/L 1551/448/901 | 100 W/D/L 54/19/27 | 100 Steps 68.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                      | 2960/10000 [04:08<09:42, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New maximum rewards: 2074.0.\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                      | 2966/10000 [04:09<09:56, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New maximum rewards: 2082.0.\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▉                                                      | 2974/10000 [04:09<09:51, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New maximum rewards: 2088.0.\n",
      "Saving model...\n",
      "New maximum rewards: 2092.0.\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▉                                                      | 2976/10000 [04:10<09:56, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New maximum rewards: 2093.0.\n",
      "Saving model...\n",
      "New maximum rewards: 2094.0.\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▉                                                      | 2980/10000 [04:10<09:58, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New maximum rewards: 2098.0.\n",
      "Saving model...\n",
      "New maximum rewards: 2104.0.\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████                                                      | 3002/10000 [04:12<09:37, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2999/10000 | Last 100 Reward 2073.0 | Last 100 Cheese 1994.5| W/D/L 1615/459/926 | 100 W/D/L 64/11/25 | 100 Steps 68.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▉                                                     | 3102/10000 [04:20<09:50, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3099/10000 | Last 100 Reward 2046.0 | Last 100 Cheese 1982.5| W/D/L 1682/468/950 | 100 W/D/L 67/9/24 | 100 Steps 66.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                    | 3202/10000 [04:28<09:15, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3199/10000 | Last 100 Reward 1993.0 | Last 100 Cheese 1950.0| W/D/L 1735/483/982 | 100 W/D/L 53/15/32 | 100 Steps 68.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████▍                                                   | 3302/10000 [04:37<09:08, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3299/10000 | Last 100 Reward 2007.0 | Last 100 Cheese 1971.5| W/D/L 1790/501/1009 | 100 W/D/L 55/18/27 | 100 Steps 68.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▏                                                  | 3402/10000 [04:45<09:07, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3399/10000 | Last 100 Reward 1998.0 | Last 100 Cheese 1960.5| W/D/L 1843/513/1044 | 100 W/D/L 53/12/35 | 100 Steps 66.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▉                                                  | 3502/10000 [04:54<08:51, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3499/10000 | Last 100 Reward 1949.0 | Last 100 Cheese 1906.5| W/D/L 1887/524/1089 | 100 W/D/L 44/11/45 | 100 Steps 70.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▋                                                 | 3602/10000 [05:02<08:52, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3599/10000 | Last 100 Reward 2073.0 | Last 100 Cheese 1995.5| W/D/L 1949/535/1116 | 100 W/D/L 62/11/27 | 100 Steps 68.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████▌                                                | 3702/10000 [05:11<08:51, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3699/10000 | Last 100 Reward 2063.0 | Last 100 Cheese 1982.5| W/D/L 2016/543/1141 | 100 W/D/L 67/8/25 | 100 Steps 67.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████▎                                               | 3802/10000 [05:19<08:30, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3799/10000 | Last 100 Reward 2045.0 | Last 100 Cheese 1990.0| W/D/L 2076/558/1166 | 100 W/D/L 60/15/25 | 100 Steps 68.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████                                               | 3902/10000 [05:27<08:22, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3899/10000 | Last 100 Reward 2033.0 | Last 100 Cheese 1973.0| W/D/L 2133/573/1194 | 100 W/D/L 57/15/28 | 100 Steps 67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                              | 4002/10000 [05:36<08:35, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3999/10000 | Last 100 Reward 1993.0 | Last 100 Cheese 1960.5| W/D/L 2188/589/1223 | 100 W/D/L 55/16/29 | 100 Steps 67.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████▌                                             | 4102/10000 [05:44<08:28, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4099/10000 | Last 100 Reward 2015.0 | Last 100 Cheese 1972.0| W/D/L 2242/601/1257 | 100 W/D/L 54/12/34 | 100 Steps 67.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▎                                            | 4202/10000 [05:52<07:54, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4199/10000 | Last 100 Reward 1984.0 | Last 100 Cheese 1944.0| W/D/L 2298/611/1291 | 100 W/D/L 56/10/34 | 100 Steps 67.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▏                                           | 4302/10000 [06:01<08:02, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4299/10000 | Last 100 Reward 1988.0 | Last 100 Cheese 1953.5| W/D/L 2351/625/1324 | 100 W/D/L 53/14/33 | 100 Steps 70.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▉                                           | 4402/10000 [06:09<08:07, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4399/10000 | Last 100 Reward 2018.0 | Last 100 Cheese 1967.5| W/D/L 2408/640/1352 | 100 W/D/L 57/15/28 | 100 Steps 69.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▋                                          | 4500/10000 [06:17<07:42, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4499/10000 | Last 100 Reward 2017.0 | Last 100 Cheese 1967.0| W/D/L 2471/647/1382 | 100 W/D/L 63/7/30 | 100 Steps 66.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████▍                                         | 4602/10000 [06:26<07:36, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4599/10000 | Last 100 Reward 1968.0 | Last 100 Cheese 1936.0| W/D/L 2519/662/1419 | 100 W/D/L 48/15/37 | 100 Steps 68.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████▏                                        | 4702/10000 [06:34<07:31, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4699/10000 | Last 100 Reward 2025.0 | Last 100 Cheese 1976.5| W/D/L 2575/674/1451 | 100 W/D/L 56/12/32 | 100 Steps 67.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████▉                                        | 4802/10000 [06:43<07:26, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4799/10000 | Last 100 Reward 2073.0 | Last 100 Cheese 2013.5| W/D/L 2635/694/1471 | 100 W/D/L 60/20/20 | 100 Steps 68.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████▋                                       | 4900/10000 [06:51<06:56, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4899/10000 | Last 100 Reward 2013.0 | Last 100 Cheese 1967.5| W/D/L 2695/710/1495 | 100 W/D/L 60/16/24 | 100 Steps 67.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▌                                      | 5002/10000 [07:00<07:10, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4999/10000 | Last 100 Reward 2052.0 | Last 100 Cheese 1984.5| W/D/L 2756/721/1523 | 100 W/D/L 61/11/28 | 100 Steps 70.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████▎                                     | 5100/10000 [07:08<06:43, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5099/10000 | Last 100 Reward 2034.0 | Last 100 Cheese 1977.0| W/D/L 2818/733/1549 | 100 W/D/L 62/12/26 | 100 Steps 67.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████                                     | 5202/10000 [07:16<07:00, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5199/10000 | Last 100 Reward 1979.0 | Last 100 Cheese 1942.5| W/D/L 2871/746/1583 | 100 W/D/L 53/13/34 | 100 Steps 67.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████████▊                                    | 5302/10000 [07:25<06:40, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5299/10000 | Last 100 Reward 2012.0 | Last 100 Cheese 1970.5| W/D/L 2924/762/1614 | 100 W/D/L 53/16/31 | 100 Steps 70.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████▌                                   | 5402/10000 [07:33<06:23, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5399/10000 | Last 100 Reward 2025.0 | Last 100 Cheese 1974.0| W/D/L 2986/769/1645 | 100 W/D/L 62/7/31 | 100 Steps 68.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████▎                                  | 5500/10000 [07:42<06:14, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5499/10000 | Last 100 Reward 1977.0 | Last 100 Cheese 1953.0| W/D/L 3033/787/1680 | 100 W/D/L 47/18/35 | 100 Steps 68.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████                                  | 5600/10000 [07:50<06:08, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5599/10000 | Last 100 Reward 1999.0 | Last 100 Cheese 1954.0| W/D/L 3079/806/1715 | 100 W/D/L 46/19/35 | 100 Steps 67.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████▉                                 | 5702/10000 [07:59<06:03, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5699/10000 | Last 100 Reward 2075.0 | Last 100 Cheese 1987.5| W/D/L 3136/822/1742 | 100 W/D/L 57/16/27 | 100 Steps 68.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████▋                                | 5802/10000 [08:07<05:43, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5799/10000 | Last 100 Reward 2040.0 | Last 100 Cheese 1973.5| W/D/L 3193/836/1771 | 100 W/D/L 57/14/29 | 100 Steps 66.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████▍                               | 5902/10000 [08:15<05:42, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5899/10000 | Last 100 Reward 1994.0 | Last 100 Cheese 1967.0| W/D/L 3242/858/1800 | 100 W/D/L 49/22/29 | 100 Steps 67.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▏                              | 6002/10000 [08:24<05:38, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5999/10000 | Last 100 Reward 2009.0 | Last 100 Cheese 1959.5| W/D/L 3292/879/1829 | 100 W/D/L 50/21/29 | 100 Steps 69.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████▉                              | 6102/10000 [08:32<05:29, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6099/10000 | Last 100 Reward 2006.0 | Last 100 Cheese 1966.0| W/D/L 3345/896/1859 | 100 W/D/L 53/17/30 | 100 Steps 69.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████▊                             | 6202/10000 [08:41<05:22, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6199/10000 | Last 100 Reward 2074.0 | Last 100 Cheese 1990.0| W/D/L 3408/913/1879 | 100 W/D/L 63/17/20 | 100 Steps 68.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████████▌                            | 6302/10000 [08:49<05:03, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6299/10000 | Last 100 Reward 2037.0 | Last 100 Cheese 1988.0| W/D/L 3469/926/1905 | 100 W/D/L 61/13/26 | 100 Steps 66.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████████▎                           | 6402/10000 [08:57<04:55, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6399/10000 | Last 100 Reward 1976.0 | Last 100 Cheese 1943.0| W/D/L 3521/942/1937 | 100 W/D/L 52/16/32 | 100 Steps 68.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████████████████████████████                           | 6502/10000 [09:06<04:55, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6499/10000 | Last 100 Reward 2049.0 | Last 100 Cheese 1981.5| W/D/L 3576/957/1967 | 100 W/D/L 55/15/30 | 100 Steps 68.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████▊                          | 6602/10000 [09:14<04:36, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6599/10000 | Last 100 Reward 1991.0 | Last 100 Cheese 1950.5| W/D/L 3627/970/2003 | 100 W/D/L 51/13/36 | 100 Steps 69.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████▌                         | 6700/10000 [09:22<04:44, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6699/10000 | Last 100 Reward 2091.0 | Last 100 Cheese 2011.0| W/D/L 3692/980/2028 | 100 W/D/L 65/10/25 | 100 Steps 66.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▍                        | 6802/10000 [09:31<04:42, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6799/10000 | Last 100 Reward 2067.0 | Last 100 Cheese 1988.0| W/D/L 3754/995/2051 | 100 W/D/L 62/15/23 | 100 Steps 67.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████████████████████████████▏                       | 6900/10000 [09:39<04:11, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6899/10000 | Last 100 Reward 2019.0 | Last 100 Cheese 1973.5| W/D/L 3815/1006/2079 | 100 W/D/L 61/11/28 | 100 Steps 65.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▉                       | 7002/10000 [09:48<04:11, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6999/10000 | Last 100 Reward 1972.0 | Last 100 Cheese 1933.5| W/D/L 3870/1019/2111 | 100 W/D/L 55/13/32 | 100 Steps 68.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████▋                      | 7102/10000 [09:57<04:09, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7099/10000 | Last 100 Reward 2043.0 | Last 100 Cheese 1969.0| W/D/L 3925/1037/2138 | 100 W/D/L 55/18/27 | 100 Steps 68.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████▍                     | 7202/10000 [10:05<03:48, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7199/10000 | Last 100 Reward 2013.0 | Last 100 Cheese 1962.0| W/D/L 3976/1056/2168 | 100 W/D/L 51/19/30 | 100 Steps 68.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████▏                    | 7300/10000 [10:13<03:48, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7299/10000 | Last 100 Reward 2001.0 | Last 100 Cheese 1965.0| W/D/L 4033/1069/2198 | 100 W/D/L 57/13/30 | 100 Steps 68.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████▉                    | 7400/10000 [10:22<03:39, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7399/10000 | Last 100 Reward 1965.0 | Last 100 Cheese 1917.5| W/D/L 4079/1082/2239 | 100 W/D/L 46/13/41 | 100 Steps 68.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████▊                   | 7502/10000 [10:30<03:29, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7499/10000 | Last 100 Reward 2025.0 | Last 100 Cheese 1966.5| W/D/L 4135/1098/2267 | 100 W/D/L 56/16/28 | 100 Steps 67.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████▌                  | 7602/10000 [10:39<03:13, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7599/10000 | Last 100 Reward 1976.0 | Last 100 Cheese 1931.5| W/D/L 4188/1107/2305 | 100 W/D/L 53/9/38 | 100 Steps 64.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████▎                 | 7702/10000 [10:47<03:15, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7699/10000 | Last 100 Reward 2001.0 | Last 100 Cheese 1963.5| W/D/L 4243/1122/2335 | 100 W/D/L 55/15/30 | 100 Steps 66.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████                 | 7800/10000 [10:55<03:01, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7799/10000 | Last 100 Reward 1999.0 | Last 100 Cheese 1969.0| W/D/L 4293/1138/2369 | 100 W/D/L 50/16/34 | 100 Steps 68.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████▊                | 7902/10000 [11:04<02:48, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7899/10000 | Last 100 Reward 1993.0 | Last 100 Cheese 1967.5| W/D/L 4341/1154/2405 | 100 W/D/L 48/16/36 | 100 Steps 69.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████▌               | 8000/10000 [11:12<02:58, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7999/10000 | Last 100 Reward 2020.0 | Last 100 Cheese 1962.0| W/D/L 4395/1170/2435 | 100 W/D/L 54/16/30 | 100 Steps 67.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████▍              | 8102/10000 [11:21<02:38, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8099/10000 | Last 100 Reward 2044.0 | Last 100 Cheese 1987.0| W/D/L 4453/1181/2466 | 100 W/D/L 58/11/31 | 100 Steps 68.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████▏             | 8202/10000 [11:29<02:31, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8199/10000 | Last 100 Reward 1962.0 | Last 100 Cheese 1921.0| W/D/L 4500/1192/2508 | 100 W/D/L 47/11/42 | 100 Steps 67.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████▉             | 8302/10000 [11:38<02:18, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8299/10000 | Last 100 Reward 1937.0 | Last 100 Cheese 1912.5| W/D/L 4547/1201/2552 | 100 W/D/L 47/9/44 | 100 Steps 68.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████▋            | 8402/10000 [11:46<02:13, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8399/10000 | Last 100 Reward 2046.0 | Last 100 Cheese 1993.0| W/D/L 4606/1215/2579 | 100 W/D/L 59/14/27 | 100 Steps 67.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████▍           | 8502/10000 [11:54<02:04, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8499/10000 | Last 100 Reward 2008.0 | Last 100 Cheese 1960.5| W/D/L 4664/1227/2609 | 100 W/D/L 58/12/30 | 100 Steps 67.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████▏          | 8600/10000 [12:03<01:57, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8599/10000 | Last 100 Reward 1999.0 | Last 100 Cheese 1953.5| W/D/L 4720/1236/2644 | 100 W/D/L 56/9/35 | 100 Steps 67.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████          | 8702/10000 [12:11<01:46, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8699/10000 | Last 100 Reward 2054.0 | Last 100 Cheese 1993.5| W/D/L 4779/1257/2664 | 100 W/D/L 59/21/20 | 100 Steps 68.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████▊         | 8800/10000 [12:19<01:40, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8799/10000 | Last 100 Reward 2030.0 | Last 100 Cheese 1974.5| W/D/L 4833/1272/2695 | 100 W/D/L 54/15/31 | 100 Steps 69.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████▌        | 8902/10000 [12:28<01:32, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8899/10000 | Last 100 Reward 1997.0 | Last 100 Cheese 1931.0| W/D/L 4889/1285/2726 | 100 W/D/L 56/13/31 | 100 Steps 66.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████▎       | 9002/10000 [12:36<01:24, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8999/10000 | Last 100 Reward 2006.0 | Last 100 Cheese 1956.0| W/D/L 4941/1302/2757 | 100 W/D/L 52/17/31 | 100 Steps 68.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████       | 9102/10000 [12:45<01:13, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9099/10000 | Last 100 Reward 2004.0 | Last 100 Cheese 1943.5| W/D/L 5000/1313/2787 | 100 W/D/L 59/11/30 | 100 Steps 65.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████▊      | 9202/10000 [12:53<01:06, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9199/10000 | Last 100 Reward 1988.0 | Last 100 Cheese 1960.0| W/D/L 5053/1331/2816 | 100 W/D/L 53/18/29 | 100 Steps 67.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████▋     | 9302/10000 [13:02<00:56, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9299/10000 | Last 100 Reward 2011.0 | Last 100 Cheese 1946.5| W/D/L 5101/1346/2853 | 100 W/D/L 48/15/37 | 100 Steps 69.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████▍    | 9402/10000 [13:10<00:48, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9399/10000 | Last 100 Reward 2055.0 | Last 100 Cheese 1987.5| W/D/L 5163/1364/2873 | 100 W/D/L 62/18/20 | 100 Steps 66.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████▏   | 9500/10000 [13:18<00:41, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9499/10000 | Last 100 Reward 2020.0 | Last 100 Cheese 1973.0| W/D/L 5223/1376/2901 | 100 W/D/L 60/12/28 | 100 Steps 66.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████▉   | 9602/10000 [13:27<00:33, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9599/10000 | Last 100 Reward 2020.0 | Last 100 Cheese 1977.5| W/D/L 5277/1393/2930 | 100 W/D/L 54/17/29 | 100 Steps 66.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████▋  | 9702/10000 [13:35<00:24, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9699/10000 | Last 100 Reward 2009.0 | Last 100 Cheese 1957.5| W/D/L 5323/1412/2965 | 100 W/D/L 46/19/35 | 100 Steps 69.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████▍ | 9802/10000 [13:44<00:16, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9799/10000 | Last 100 Reward 2023.0 | Last 100 Cheese 1960.0| W/D/L 5375/1430/2995 | 100 W/D/L 52/18/30 | 100 Steps 69.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████▏| 9902/10000 [13:52<00:08, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9899/10000 | Last 100 Reward 1989.0 | Last 100 Cheese 1951.5| W/D/L 5425/1448/3027 | 100 W/D/L 50/18/32 | 100 Steps 66.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [14:00<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9999/10000 | Last 100 Reward 2014.0 | Last 100 Cheese 1964.0| W/D/L 5483/1461/3056 | 100 W/D/L 58/13/29 | 100 Steps 66.31\n",
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 10000  # Total number of epochs that will be done\n",
    "\n",
    "print(\"Training\")\n",
    "play(model, epoch, criterion, optimizer, True)\n",
    "print(\"Training done\")\n",
    "\n",
    "#model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0CT-rVq94CK"
   },
   "source": [
    "### Evaluate the Q-learner model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performant weight parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate previous model\n",
    "load = True\n",
    "\n",
    "if load:\n",
    "    model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7DV0r-w194kt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                             | 108/10000 [00:01<02:30, 65.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 099/10000 | Last 100 Reward 1989.0 | Last 100 Cheese 1956.0| W/D/L 47/16/37 | 100 W/D/L 47/16/37 | 100 Steps 68.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                            | 210/10000 [00:03<02:18, 70.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/10000 | Last 100 Reward 2006.0 | Last 100 Cheese 1960.5| W/D/L 102/24/74 | 100 W/D/L 55/8/37 | 100 Steps 67.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                           | 312/10000 [00:04<02:15, 71.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/10000 | Last 100 Reward 2071.0 | Last 100 Cheese 2002.0| W/D/L 164/37/99 | 100 W/D/L 62/13/25 | 100 Steps 67.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                          | 411/10000 [00:05<02:22, 67.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/10000 | Last 100 Reward 2031.0 | Last 100 Cheese 1981.5| W/D/L 220/54/126 | 100 W/D/L 56/17/27 | 100 Steps 69.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                          | 510/10000 [00:07<02:10, 72.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/10000 | Last 100 Reward 2050.0 | Last 100 Cheese 1984.0| W/D/L 283/63/154 | 100 W/D/L 63/9/28 | 100 Steps 67.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                         | 608/10000 [00:08<02:11, 71.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/10000 | Last 100 Reward 2012.0 | Last 100 Cheese 1961.5| W/D/L 347/70/183 | 100 W/D/L 64/7/29 | 100 Steps 66.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▌                                                                        | 713/10000 [00:10<02:07, 73.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699/10000 | Last 100 Reward 2028.0 | Last 100 Cheese 1974.0| W/D/L 405/79/216 | 100 W/D/L 58/9/33 | 100 Steps 67.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                       | 808/10000 [00:11<02:17, 66.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/10000 | Last 100 Reward 2039.0 | Last 100 Cheese 1972.0| W/D/L 462/96/242 | 100 W/D/L 57/17/26 | 100 Steps 67.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████                                                                       | 912/10000 [00:13<02:11, 69.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/10000 | Last 100 Reward 2059.0 | Last 100 Cheese 2000.5| W/D/L 522/113/265 | 100 W/D/L 60/17/23 | 100 Steps 69.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                     | 1007/10000 [00:14<02:20, 64.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/10000 | Last 100 Reward 2008.0 | Last 100 Cheese 1967.5| W/D/L 577/128/295 | 100 W/D/L 55/15/30 | 100 Steps 69.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▌                                                                    | 1110/10000 [00:16<02:10, 68.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1099/10000 | Last 100 Reward 1984.0 | Last 100 Cheese 1965.5| W/D/L 624/142/334 | 100 W/D/L 47/14/39 | 100 Steps 69.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▎                                                                   | 1210/10000 [00:17<02:01, 72.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/10000 | Last 100 Reward 2031.0 | Last 100 Cheese 1986.0| W/D/L 682/162/356 | 100 W/D/L 58/20/22 | 100 Steps 66.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████                                                                   | 1307/10000 [00:18<02:08, 67.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1299/10000 | Last 100 Reward 2033.0 | Last 100 Cheese 1972.5| W/D/L 739/174/387 | 100 W/D/L 57/12/31 | 100 Steps 66.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▊                                                                  | 1410/10000 [00:20<02:08, 66.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1399/10000 | Last 100 Reward 1967.0 | Last 100 Cheese 1932.0| W/D/L 787/189/424 | 100 W/D/L 48/15/37 | 100 Steps 68.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▋                                                                 | 1510/10000 [00:22<02:08, 65.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1499/10000 | Last 100 Reward 2052.0 | Last 100 Cheese 1996.0| W/D/L 845/206/449 | 100 W/D/L 58/17/25 | 100 Steps 69.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▎                                                                | 1607/10000 [00:23<02:09, 64.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1599/10000 | Last 100 Reward 2044.0 | Last 100 Cheese 1995.5| W/D/L 902/224/474 | 100 W/D/L 57/18/25 | 100 Steps 67.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▏                                                               | 1708/10000 [00:25<02:07, 65.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1699/10000 | Last 100 Reward 2052.0 | Last 100 Cheese 1977.0| W/D/L 962/238/500 | 100 W/D/L 60/14/26 | 100 Steps 69.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▉                                                               | 1808/10000 [00:26<02:10, 62.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1799/10000 | Last 100 Reward 2017.0 | Last 100 Cheese 1970.0| W/D/L 1018/253/529 | 100 W/D/L 56/15/29 | 100 Steps 70.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▋                                                              | 1906/10000 [00:28<02:25, 55.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1899/10000 | Last 100 Reward 2056.0 | Last 100 Cheese 1994.0| W/D/L 1074/269/557 | 100 W/D/L 56/16/28 | 100 Steps 71.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 2008/10000 [00:29<01:53, 70.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1999/10000 | Last 100 Reward 2006.0 | Last 100 Cheese 1949.5| W/D/L 1131/281/588 | 100 W/D/L 57/12/31 | 100 Steps 65.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▏                                                            | 2106/10000 [00:31<01:58, 66.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2099/10000 | Last 100 Reward 2060.0 | Last 100 Cheese 1988.0| W/D/L 1187/298/615 | 100 W/D/L 56/17/27 | 100 Steps 69.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████                                                            | 2208/10000 [00:32<01:53, 68.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2199/10000 | Last 100 Reward 2063.0 | Last 100 Cheese 1993.5| W/D/L 1247/312/641 | 100 W/D/L 60/14/26 | 100 Steps 68.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▊                                                           | 2312/10000 [00:34<01:51, 69.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2299/10000 | Last 100 Reward 1998.0 | Last 100 Cheese 1947.5| W/D/L 1303/324/673 | 100 W/D/L 56/12/32 | 100 Steps 66.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▌                                                          | 2408/10000 [00:35<01:52, 67.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2399/10000 | Last 100 Reward 2044.0 | Last 100 Cheese 1975.5| W/D/L 1367/331/702 | 100 W/D/L 64/7/29 | 100 Steps 68.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▎                                                         | 2511/10000 [00:37<01:55, 64.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2499/10000 | Last 100 Reward 2030.0 | Last 100 Cheese 1978.0| W/D/L 1426/345/729 | 100 W/D/L 59/14/27 | 100 Steps 68.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████                                                         | 2608/10000 [00:38<01:53, 65.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2599/10000 | Last 100 Reward 2024.0 | Last 100 Cheese 1975.0| W/D/L 1484/357/759 | 100 W/D/L 58/12/30 | 100 Steps 66.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▊                                                        | 2706/10000 [00:39<01:46, 68.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2699/10000 | Last 100 Reward 1983.0 | Last 100 Cheese 1946.5| W/D/L 1537/371/792 | 100 W/D/L 53/14/33 | 100 Steps 67.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▋                                                       | 2810/10000 [00:41<01:50, 65.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2799/10000 | Last 100 Reward 2060.0 | Last 100 Cheese 1996.0| W/D/L 1601/383/816 | 100 W/D/L 64/12/24 | 100 Steps 67.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████▍                                                      | 2908/10000 [00:43<01:42, 69.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2899/10000 | Last 100 Reward 2041.0 | Last 100 Cheese 1991.5| W/D/L 1657/405/838 | 100 W/D/L 56/22/22 | 100 Steps 68.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▏                                                     | 3009/10000 [00:44<01:47, 64.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2999/10000 | Last 100 Reward 2010.0 | Last 100 Cheese 1951.0| W/D/L 1709/417/874 | 100 W/D/L 52/12/36 | 100 Steps 68.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▉                                                     | 3113/10000 [00:46<01:46, 64.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3099/10000 | Last 100 Reward 2024.0 | Last 100 Cheese 1985.5| W/D/L 1765/433/902 | 100 W/D/L 56/16/28 | 100 Steps 68.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                    | 3209/10000 [00:47<01:40, 67.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3199/10000 | Last 100 Reward 1999.0 | Last 100 Cheese 1953.0| W/D/L 1818/446/936 | 100 W/D/L 53/13/34 | 100 Steps 68.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████▍                                                   | 3310/10000 [00:49<01:44, 64.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3299/10000 | Last 100 Reward 2047.0 | Last 100 Cheese 1992.5| W/D/L 1877/465/958 | 100 W/D/L 59/19/22 | 100 Steps 68.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▏                                                  | 3406/10000 [00:50<01:46, 61.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3399/10000 | Last 100 Reward 2017.0 | Last 100 Cheese 1969.5| W/D/L 1933/474/993 | 100 W/D/L 56/9/35 | 100 Steps 68.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████                                                  | 3508/10000 [00:52<01:42, 63.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3499/10000 | Last 100 Reward 2050.0 | Last 100 Cheese 2009.0| W/D/L 1995/491/1014 | 100 W/D/L 62/17/21 | 100 Steps 66.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▊                                                 | 3605/10000 [00:53<01:34, 67.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3599/10000 | Last 100 Reward 2018.0 | Last 100 Cheese 1958.5| W/D/L 2054/501/1045 | 100 W/D/L 59/10/31 | 100 Steps 67.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████▌                                                | 3710/10000 [00:55<01:27, 71.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3699/10000 | Last 100 Reward 2028.0 | Last 100 Cheese 1976.0| W/D/L 2112/515/1073 | 100 W/D/L 58/14/28 | 100 Steps 67.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████▎                                               | 3808/10000 [00:56<01:33, 66.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3799/10000 | Last 100 Reward 1996.0 | Last 100 Cheese 1954.0| W/D/L 2169/528/1103 | 100 W/D/L 57/13/30 | 100 Steps 66.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████                                               | 3905/10000 [00:58<01:46, 57.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3899/10000 | Last 100 Reward 2032.0 | Last 100 Cheese 1982.0| W/D/L 2230/541/1129 | 100 W/D/L 61/13/26 | 100 Steps 66.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                              | 4004/10000 [00:59<01:37, 61.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3999/10000 | Last 100 Reward 2017.0 | Last 100 Cheese 1964.5| W/D/L 2286/554/1160 | 100 W/D/L 56/13/31 | 100 Steps 69.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████▋                                             | 4109/10000 [01:01<01:31, 64.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4099/10000 | Last 100 Reward 1967.0 | Last 100 Cheese 1935.5| W/D/L 2332/569/1199 | 100 W/D/L 46/15/39 | 100 Steps 67.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▍                                            | 4209/10000 [01:03<01:25, 67.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4199/10000 | Last 100 Reward 2044.0 | Last 100 Cheese 1974.5| W/D/L 2390/583/1227 | 100 W/D/L 58/14/28 | 100 Steps 67.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▏                                           | 4307/10000 [01:04<01:34, 60.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4299/10000 | Last 100 Reward 1989.0 | Last 100 Cheese 1955.0| W/D/L 2445/596/1259 | 100 W/D/L 55/13/32 | 100 Steps 67.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▉                                           | 4411/10000 [01:06<01:23, 66.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4399/10000 | Last 100 Reward 2047.0 | Last 100 Cheese 1982.5| W/D/L 2505/605/1290 | 100 W/D/L 60/9/31 | 100 Steps 68.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▋                                          | 4510/10000 [01:08<01:25, 64.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4499/10000 | Last 100 Reward 2042.0 | Last 100 Cheese 1977.5| W/D/L 2566/615/1319 | 100 W/D/L 61/10/29 | 100 Steps 67.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████▍                                         | 4607/10000 [01:09<01:19, 67.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4599/10000 | Last 100 Reward 2009.0 | Last 100 Cheese 1958.0| W/D/L 2618/633/1349 | 100 W/D/L 52/18/30 | 100 Steps 68.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████▎                                        | 4714/10000 [01:11<01:18, 67.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4699/10000 | Last 100 Reward 2006.0 | Last 100 Cheese 1955.0| W/D/L 2673/648/1379 | 100 W/D/L 55/15/30 | 100 Steps 65.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████                                        | 4811/10000 [01:12<01:23, 62.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4799/10000 | Last 100 Reward 2051.0 | Last 100 Cheese 1993.0| W/D/L 2731/663/1406 | 100 W/D/L 58/15/27 | 100 Steps 66.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████▊                                       | 4910/10000 [01:14<01:16, 66.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4899/10000 | Last 100 Reward 2052.0 | Last 100 Cheese 1994.0| W/D/L 2791/678/1431 | 100 W/D/L 60/15/25 | 100 Steps 65.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▌                                      | 5009/10000 [01:15<01:14, 67.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4999/10000 | Last 100 Reward 1978.0 | Last 100 Cheese 1945.5| W/D/L 2845/690/1465 | 100 W/D/L 54/12/34 | 100 Steps 66.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████▎                                     | 5110/10000 [01:17<01:14, 66.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5099/10000 | Last 100 Reward 2055.0 | Last 100 Cheese 1986.5| W/D/L 2901/708/1491 | 100 W/D/L 56/18/26 | 100 Steps 68.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████                                     | 5211/10000 [01:18<01:16, 62.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5199/10000 | Last 100 Reward 2057.0 | Last 100 Cheese 1998.0| W/D/L 2961/722/1517 | 100 W/D/L 60/14/26 | 100 Steps 68.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████████▊                                    | 5308/10000 [01:20<01:09, 67.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5299/10000 | Last 100 Reward 2033.0 | Last 100 Cheese 1975.5| W/D/L 3015/738/1547 | 100 W/D/L 54/16/30 | 100 Steps 67.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████▋                                   | 5408/10000 [01:21<01:06, 69.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5399/10000 | Last 100 Reward 2061.0 | Last 100 Cheese 2000.0| W/D/L 3081/749/1570 | 100 W/D/L 66/11/23 | 100 Steps 67.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████▍                                  | 5509/10000 [01:23<01:07, 66.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5499/10000 | Last 100 Reward 1986.0 | Last 100 Cheese 1958.0| W/D/L 3124/771/1605 | 100 W/D/L 43/22/35 | 100 Steps 70.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████▏                                 | 5607/10000 [01:24<01:04, 67.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5599/10000 | Last 100 Reward 1984.0 | Last 100 Cheese 1939.0| W/D/L 3181/780/1639 | 100 W/D/L 57/9/34 | 100 Steps 67.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████▉                                 | 5709/10000 [01:26<01:06, 64.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5699/10000 | Last 100 Reward 2013.0 | Last 100 Cheese 1970.5| W/D/L 3234/795/1671 | 100 W/D/L 53/15/32 | 100 Steps 68.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████▋                                | 5808/10000 [01:27<01:02, 67.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5799/10000 | Last 100 Reward 2033.0 | Last 100 Cheese 1984.5| W/D/L 3290/812/1698 | 100 W/D/L 56/17/27 | 100 Steps 68.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████▍                               | 5906/10000 [01:29<00:57, 70.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5899/10000 | Last 100 Reward 2017.0 | Last 100 Cheese 1963.0| W/D/L 3342/831/1727 | 100 W/D/L 52/19/29 | 100 Steps 68.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▎                              | 6010/10000 [01:30<00:57, 69.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5999/10000 | Last 100 Reward 2047.0 | Last 100 Cheese 1982.0| W/D/L 3400/846/1754 | 100 W/D/L 58/15/27 | 100 Steps 66.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████                              | 6109/10000 [01:32<01:00, 63.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6099/10000 | Last 100 Reward 2082.0 | Last 100 Cheese 1995.0| W/D/L 3463/857/1780 | 100 W/D/L 63/11/26 | 100 Steps 69.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████▊                             | 6209/10000 [01:33<00:58, 65.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6199/10000 | Last 100 Reward 2010.0 | Last 100 Cheese 1972.5| W/D/L 3514/875/1811 | 100 W/D/L 51/18/31 | 100 Steps 70.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████████▌                            | 6312/10000 [01:35<00:54, 67.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6299/10000 | Last 100 Reward 1978.0 | Last 100 Cheese 1953.5| W/D/L 3564/887/1849 | 100 W/D/L 50/12/38 | 100 Steps 66.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████████▎                           | 6408/10000 [01:36<00:52, 68.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6399/10000 | Last 100 Reward 2046.0 | Last 100 Cheese 2003.0| W/D/L 3621/903/1876 | 100 W/D/L 57/16/27 | 100 Steps 69.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████████████████████████████▏                          | 6513/10000 [01:38<00:51, 67.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6499/10000 | Last 100 Reward 2028.0 | Last 100 Cheese 1975.5| W/D/L 3679/913/1908 | 100 W/D/L 58/10/32 | 100 Steps 67.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████▉                          | 6608/10000 [01:39<00:50, 66.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6599/10000 | Last 100 Reward 2034.0 | Last 100 Cheese 1975.5| W/D/L 3737/923/1940 | 100 W/D/L 58/10/32 | 100 Steps 68.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████▋                         | 6712/10000 [01:41<00:45, 72.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6699/10000 | Last 100 Reward 1991.0 | Last 100 Cheese 1961.0| W/D/L 3790/942/1968 | 100 W/D/L 53/19/28 | 100 Steps 67.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▍                        | 6807/10000 [01:42<00:49, 64.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6799/10000 | Last 100 Reward 1994.0 | Last 100 Cheese 1953.0| W/D/L 3843/961/1996 | 100 W/D/L 53/19/28 | 100 Steps 67.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████████████████████████████▏                       | 6904/10000 [01:44<00:47, 64.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6899/10000 | Last 100 Reward 2022.0 | Last 100 Cheese 1970.5| W/D/L 3903/968/2029 | 100 W/D/L 60/7/33 | 100 Steps 67.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▉                       | 7006/10000 [01:45<00:46, 65.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6999/10000 | Last 100 Reward 2004.0 | Last 100 Cheese 1957.0| W/D/L 3956/986/2058 | 100 W/D/L 53/18/29 | 100 Steps 68.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████▊                      | 7113/10000 [01:47<00:39, 72.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7099/10000 | Last 100 Reward 1984.0 | Last 100 Cheese 1945.5| W/D/L 4011/1000/2089 | 100 W/D/L 55/14/31 | 100 Steps 65.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████▍                     | 7206/10000 [01:48<00:42, 65.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7199/10000 | Last 100 Reward 2042.0 | Last 100 Cheese 1978.0| W/D/L 4071/1015/2114 | 100 W/D/L 60/15/25 | 100 Steps 68.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████▎                    | 7309/10000 [01:50<00:40, 66.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7299/10000 | Last 100 Reward 2040.0 | Last 100 Cheese 1993.0| W/D/L 4131/1031/2138 | 100 W/D/L 60/16/24 | 100 Steps 66.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████                    | 7408/10000 [01:51<00:35, 72.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7399/10000 | Last 100 Reward 2025.0 | Last 100 Cheese 1966.5| W/D/L 4187/1044/2169 | 100 W/D/L 56/13/31 | 100 Steps 66.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████▊                   | 7511/10000 [01:53<00:36, 67.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7499/10000 | Last 100 Reward 2033.0 | Last 100 Cheese 1984.5| W/D/L 4244/1058/2198 | 100 W/D/L 57/14/29 | 100 Steps 67.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████▌                  | 7612/10000 [01:54<00:34, 69.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7599/10000 | Last 100 Reward 2046.0 | Last 100 Cheese 1986.0| W/D/L 4308/1069/2223 | 100 W/D/L 64/11/25 | 100 Steps 67.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████▎                 | 7708/10000 [01:56<00:36, 62.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7699/10000 | Last 100 Reward 1951.0 | Last 100 Cheese 1925.0| W/D/L 4356/1083/2261 | 100 W/D/L 48/14/38 | 100 Steps 66.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████▏                | 7810/10000 [01:57<00:33, 66.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7799/10000 | Last 100 Reward 2018.0 | Last 100 Cheese 1955.0| W/D/L 4413/1095/2292 | 100 W/D/L 57/12/31 | 100 Steps 67.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████▉                | 7914/10000 [01:59<00:29, 70.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7899/10000 | Last 100 Reward 2046.0 | Last 100 Cheese 1990.0| W/D/L 4474/1113/2313 | 100 W/D/L 61/18/21 | 100 Steps 65.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████▋               | 8010/10000 [02:00<00:30, 65.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7999/10000 | Last 100 Reward 1966.0 | Last 100 Cheese 1940.5| W/D/L 4526/1127/2347 | 100 W/D/L 52/14/34 | 100 Steps 68.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████▍              | 8110/10000 [02:02<00:27, 69.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8099/10000 | Last 100 Reward 2019.0 | Last 100 Cheese 1965.0| W/D/L 4585/1139/2376 | 100 W/D/L 59/12/29 | 100 Steps 66.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████▎             | 8215/10000 [02:03<00:24, 71.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8199/10000 | Last 100 Reward 2034.0 | Last 100 Cheese 1965.0| W/D/L 4639/1156/2405 | 100 W/D/L 54/17/29 | 100 Steps 68.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████▉             | 8310/10000 [02:05<00:24, 68.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8299/10000 | Last 100 Reward 2017.0 | Last 100 Cheese 1951.0| W/D/L 4698/1164/2438 | 100 W/D/L 59/8/33 | 100 Steps 67.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████▋            | 8409/10000 [02:06<00:24, 66.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8399/10000 | Last 100 Reward 2049.0 | Last 100 Cheese 1996.0| W/D/L 4753/1188/2459 | 100 W/D/L 55/24/21 | 100 Steps 69.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████▌           | 8511/10000 [02:08<00:22, 65.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8499/10000 | Last 100 Reward 2043.0 | Last 100 Cheese 1981.0| W/D/L 4815/1201/2484 | 100 W/D/L 62/13/25 | 100 Steps 66.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████▎          | 8609/10000 [02:09<00:20, 67.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8599/10000 | Last 100 Reward 2068.0 | Last 100 Cheese 1994.0| W/D/L 4878/1214/2508 | 100 W/D/L 63/13/24 | 100 Steps 66.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████          | 8706/10000 [02:10<00:18, 69.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8699/10000 | Last 100 Reward 2005.0 | Last 100 Cheese 1955.5| W/D/L 4931/1229/2540 | 100 W/D/L 53/15/32 | 100 Steps 68.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████▊         | 8809/10000 [02:12<00:17, 68.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8799/10000 | Last 100 Reward 1996.0 | Last 100 Cheese 1952.0| W/D/L 4981/1244/2575 | 100 W/D/L 50/15/35 | 100 Steps 67.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████▌        | 8905/10000 [02:13<00:17, 63.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8899/10000 | Last 100 Reward 2036.0 | Last 100 Cheese 1971.5| W/D/L 5037/1264/2599 | 100 W/D/L 56/20/24 | 100 Steps 67.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████▎       | 9007/10000 [02:15<00:15, 65.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8999/10000 | Last 100 Reward 2018.0 | Last 100 Cheese 1961.5| W/D/L 5090/1280/2630 | 100 W/D/L 53/16/31 | 100 Steps 68.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████▏      | 9113/10000 [02:17<00:13, 66.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9099/10000 | Last 100 Reward 2079.0 | Last 100 Cheese 2006.0| W/D/L 5151/1298/2651 | 100 W/D/L 61/18/21 | 100 Steps 68.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████▉      | 9213/10000 [02:18<00:12, 65.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9199/10000 | Last 100 Reward 2024.0 | Last 100 Cheese 1971.0| W/D/L 5204/1315/2681 | 100 W/D/L 53/17/30 | 100 Steps 68.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████▋     | 9311/10000 [02:20<00:10, 66.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9299/10000 | Last 100 Reward 2064.0 | Last 100 Cheese 1994.5| W/D/L 5269/1326/2705 | 100 W/D/L 65/11/24 | 100 Steps 68.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████▍    | 9410/10000 [02:21<00:08, 66.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9399/10000 | Last 100 Reward 2071.0 | Last 100 Cheese 2005.5| W/D/L 5329/1345/2726 | 100 W/D/L 60/19/21 | 100 Steps 69.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████▏   | 9508/10000 [02:22<00:07, 66.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9499/10000 | Last 100 Reward 2053.0 | Last 100 Cheese 1990.0| W/D/L 5387/1357/2756 | 100 W/D/L 58/12/30 | 100 Steps 67.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████▉   | 9609/10000 [02:24<00:05, 65.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9599/10000 | Last 100 Reward 2061.0 | Last 100 Cheese 2006.0| W/D/L 5446/1376/2778 | 100 W/D/L 59/19/22 | 100 Steps 68.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████▊  | 9708/10000 [02:26<00:04, 64.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9699/10000 | Last 100 Reward 2058.0 | Last 100 Cheese 1983.0| W/D/L 5512/1387/2801 | 100 W/D/L 66/11/23 | 100 Steps 66.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████▍ | 9805/10000 [02:27<00:02, 66.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9799/10000 | Last 100 Reward 2059.0 | Last 100 Cheese 1987.5| W/D/L 5573/1400/2827 | 100 W/D/L 61/13/26 | 100 Steps 67.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████▎| 9908/10000 [02:29<00:01, 70.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9899/10000 | Last 100 Reward 2003.0 | Last 100 Cheese 1966.5| W/D/L 5625/1410/2865 | 100 W/D/L 52/10/38 | 100 Steps 68.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:30<00:00, 66.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9999/10000 | Last 100 Reward 2050.0 | Last 100 Cheese 1984.0| W/D/L 5686/1421/2893 | 100 W/D/L 61/11/28 | 100 Steps 67.73\n",
      "Testing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 10000  # Total number of epochs that will be done\n",
    "\n",
    "print(\"Testing\")\n",
    "play(model, epoch, criterion, optimizer, False)\n",
    "print(\"Testing done\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cuda117",
   "language": "python",
   "name": "cuda117"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
